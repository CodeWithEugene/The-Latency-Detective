# ğŸ•µï¸â€â™‚ï¸ The Latency Detective  
### Profiling and Performance Optimization in High-Concurrency Node.js Systems  
A full-stack performance profiling and optimization platform built to detect, analyze, and eliminate latency bottlenecks in Node.js applications. The system benchmarks a deliberately unoptimized API, visualizes its performance under load, and then refactors it using **Worker Threads** to achieve near real-time responsiveness. Performance metrics are logged in **Supabase** and visualized through an interactive **React Dashboard** â€” expressed in **Kenyan Shillings (KSH)** to represent â€œcost of latency.â€  

## ğŸš€ Project Overview  
Node.js is fast, but single-threaded. When CPU-intensive tasks block the **Event Loop**, overall throughput drops â€” especially under high concurrency. **The Latency Detective** helps developers *see* and *solve* this problem by combining profiling, multithreading, and visualization in a single, cohesive platform.  

## ğŸ§© System Architecture  
### ğŸ—ï¸ Overview  
# ğŸ•µï¸â€â™‚ï¸ The Latency Detective â€“ System Architecture

A full-stack Node.js performance profiling and optimization system powered by Worker Threads, React (Vite/Next.js), and Supabase â€” built to analyze and visualize latency improvements in real-time (with currency metrics in KSH).

---

## ğŸ§­ System Architecture (Horizontal Overview)

| Component | Technology | Responsibilities |
|-----------|------------|------------------|
| **Frontend** | React (Vite/Next.js) | â€¢ Interactive dashboard with metrics visualization<br>â€¢ Load testing interface for 100 concurrent requests<br>â€¢ Display performance costs in Kenyan Shillings (KES) |
| **Backend** | Node.js + TypeScript + Express | â€¢ Process CPU-intensive tasks via /api/process-data<br>â€¢ Implement Worker Threads for workload offloading<br>â€¢ Collect profiling and performance metrics |
| **Database** | Supabase (PostgreSQL) | â€¢ Store latency test results and timestamps<br>â€¢ Handle user authentication (optional)<br>â€¢ Enable real-time metrics tracking with RLS |

## âš™ï¸ Tech Stack  
| Layer | Technology | Purpose |
|-------|-------------|----------|
| **Frontend** | React (Vite/Next.js), TypeScript, Tailwind CSS | Interactive performance dashboard |
| **Backend** | Node.js, Express, Worker Threads, TypeScript | API, benchmarking, and optimization |
| **Database** | Supabase (PostgreSQL) | Store latency metrics & logs |
| **Dev Tools** | Node.js Profiler, Chrome DevTools, Autocannon | Profiling and load testing |
| **Deployment** | Vercel (Frontend), Render/Railway (Backend) | Hosting and CI/CD |

## ğŸ” Features  
### ğŸ§  Phase 1: Baseline Profiling  
- Unoptimized endpoint: `POST /api/process-data`  
- Simulates CPU-heavy workload (e.g., Fibonacci sequence)  
- Measured under 100 concurrent requests  
- Uses `autocannon` for load testing  
- Captures flame graph and CPU profile  

### âš¡ Phase 2: Worker Thread Optimization  
- Offloads heavy computation to a separate thread  
- Main thread freed for I/O operations  
- Async communication with Promise-based Worker  
- Results in 90%+ reduction in latency under load  

### ğŸ“Š Phase 3: Visualization Dashboard  
- React-based dashboard for:  
  - Baseline vs Optimized latency  
  - CPU utilization graphs  
  - Throughput charts  
- Uses Recharts/Chart.js for data visualization  
- Displays performance cost in **KSH (Kenyan Shillings)**  

### ğŸ’¾ Phase 4: Metrics Logging with Supabase  
- Logs test runs: latency, concurrency level, timestamps  
- Stores optimization percentage  
- Optional Auth (JWT) for developer-only dashboard access  

## ğŸ’¡ Example Endpoints  
| Method | Endpoint | Description |
|--------|-----------|--------------|
| `POST` | `/api/process-data` | Runs CPU-intensive computation (unoptimized/optimized) |
| `GET` | `/api/metrics` | Returns average latency and improvement stats |
| `GET` | `/api/health` | Simple health check endpoint |

## ğŸ§® Example Output  
### ğŸ”´ Before Optimization  

- Average Latency: 3.8 seconds
- CPU Usage: 97%
- Event Loop Blocked: Yes
### ğŸŸ¢ After Optimization
- Average Latency: 55 milliseconds
- CPU Usage: 37%
- Event Loop Blocked: No
- Latency Improved by: 98.5%
## ğŸ› ï¸ Setup & Installation
#### 1ï¸âƒ£ Clone Repositories

- git clone https://github.com/yourusername/latency-detective-backend.git
- git clone https://github.com/yourusername/latency-detective-frontend.git
#### 2ï¸âƒ£ Backend Setup

- cd latency-detective-backend
- npm install
- cp .env.example .env
- Add your Supabase credentials
- npm run dev
#### 3ï¸âƒ£ Frontend Setup

- cd latency-detective-frontend
- npm install
- npm run dev
### ğŸ§° Load Testing
- Use autocannon to simulate concurrent requests:
- npx autocannon -c 100 -d 15 http://localhost:4000/api/process-data
### ğŸ“Š Profiling Commands
- Chrome DevTools Profiling
- node --inspect app.js
### Open chrome://inspect in Chrome and start profiling
- CLI Profiling
- node --prof app.js
- node --prof-process isolate-*.log > processed.txt
